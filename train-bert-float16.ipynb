{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets==2.15.0","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:16:58.785935Z","iopub.execute_input":"2024-02-20T06:16:58.786248Z","iopub.status.idle":"2024-02-20T06:17:15.083707Z","shell.execute_reply.started":"2024-02-20T06:16:58.786221Z","shell.execute_reply":"2024-02-20T06:17:15.082539Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting datasets==2.15.0\n  Downloading datasets-2.15.0-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (1.24.4)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (11.0.0)\nCollecting pyarrow-hotfix (from datasets==2.15.0)\n  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.3.7)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.70.15)\nCollecting fsspec<=2023.10.0,>=2023.1.0 (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets==2.15.0)\n  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (0.20.3)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.15.0) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.15.0) (4.0.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (3.13.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.18.0->datasets==2.15.0) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.15.0) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.15.0) (2023.11.17)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.15.0) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.15.0) (1.16.0)\nDownloading datasets-2.15.0-py3-none-any.whl (521 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\nInstalling collected packages: pyarrow-hotfix, fsspec, datasets\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2023.12.2\n    Uninstalling fsspec-2023.12.2:\n      Successfully uninstalled fsspec-2023.12.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.1.0\n    Uninstalling datasets-2.1.0:\n      Successfully uninstalled datasets-2.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ngcsfs 2023.12.2.post1 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.15.0 fsspec-2023.10.0 pyarrow-hotfix-0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\n\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, BertConfig\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler\nfrom torch.utils.data.distributed import DistributedSampler\nfrom datasets import load_dataset\n\nimport torch\nfrom contextlib import nullcontext\nfrom torch.cuda.amp import GradScaler, autocast\n\n\ntorch.backends.cuda.matmul.allow_tf32 = True # allow tf32 on matmul\ntorch.backends.cudnn.allow_tf32 = True # allow tf32 on cudnn\n\n# -----------------------------------------------------------------------------\n# Load the dataset\ndataset = load_dataset(\"sepidmnorozy/Vietnamese_sentiment\")\n\n# Initialize the model, tokenizer, and training settings\ntokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\nconfig = BertConfig.from_pretrained(\"bert-base-multilingual-cased\")\nmodel = BertForSequenceClassification(config)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\ncriterion = torch.nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:17:15.086158Z","iopub.execute_input":"2024-02-20T06:17:15.086896Z","iopub.status.idle":"2024-02-20T06:17:33.462143Z","shell.execute_reply.started":"2024-02-20T06:17:15.086846Z","shell.execute_reply":"2024-02-20T06:17:33.461183Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ccfbd46ec734c9dbb9719baaf782031"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/329k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e041e421a25849b2a8b73582913782dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/52.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81d9774ad29e4fadbec81068d8897828"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/99.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e80ce063d9bb4135ac080c37851a7215"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bf3b705756a43fbad0296fd2dbd505c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"814f65e2f7514677a1ad602cdbb1256c"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:765: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating validation split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76e1e8e31bb14034a7d561cad79926ac"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:765: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"965339f089cc4bee9fa9c42b0c895e19"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/download/streaming_download_manager.py:765: FutureWarning: The 'verbose' keyword in pd.read_csv is deprecated and will be removed in a future version.\n  return pd.read_csv(xopen(filepath_or_buffer, \"rb\", download_config=download_config), **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0df4cd8d26469683b3ed67ff85064e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b969b0b558664d9fa3a7ed8358196c43"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0235075ff0eb4c8cb007596e44965e77"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f94b1468f0142959612b989d435c9d4"}},"metadata":{}}]},{"cell_type":"code","source":"# Preprocess the data using the datasets library\ndef tokenize_and_encode(batch):\n    encoded = tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n    return {\n        \"input_ids\": encoded[\"input_ids\"],\n        \"attention_mask\": encoded[\"attention_mask\"],\n        \"labels\": batch[\"label\"],\n    }\n\nencoded_train_dataset = dataset[\"train\"].map(tokenize_and_encode, batched=True, remove_columns=[\"text\"])\nencoded_eval_dataset = dataset[\"test\"].map(tokenize_and_encode, batched=True, remove_columns=[\"text\"])\nencoded_train_dataset.set_format(\"torch\")\nencoded_eval_dataset.set_format(\"torch\")\n\n# Create the DataLoaders\ntrain_dataloader = DataLoader(\n    encoded_train_dataset,\n    sampler=RandomSampler(encoded_train_dataset),\n    batch_size=64,\n    collate_fn=lambda x: {\n        \"input_ids\": torch.stack([sample[\"input_ids\"] for sample in x]),\n        \"attention_mask\": torch.stack([sample[\"attention_mask\"] for sample in x]),\n        \"labels\": torch.tensor([sample[\"labels\"] for sample in x]),\n    },\n)\n\neval_dataloader = DataLoader(\n    encoded_eval_dataset,\n    sampler=SequentialSampler(encoded_eval_dataset),\n    batch_size=64,\n    collate_fn=lambda x: {\n        \"input_ids\": torch.stack([sample[\"input_ids\"] for sample in x]),\n        \"attention_mask\": torch.stack([sample[\"attention_mask\"] for sample in x]),\n        \"labels\": torch.tensor([sample[\"labels\"] for sample in x]),\n    },\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:17:33.463287Z","iopub.execute_input":"2024-02-20T06:17:33.463746Z","iopub.status.idle":"2024-02-20T06:17:40.724033Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2384 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"870ff1884c4e4082b45b02e07acbe802"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/685 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"15b49cbf601144d39392f59a30b427a9"}},"metadata":{}}]},{"cell_type":"code","source":"mixed_precision_dtype = torch.float16 # torch.bfloat16\nctx = nullcontext() if mixed_precision_dtype == None else torch.amp.autocast(device_type='cuda', dtype=mixed_precision_dtype)\n# Initialize GradScaler for mixed precision training\nscaler = GradScaler()","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:17:40.725802Z","iopub.execute_input":"2024-02-20T06:17:40.726076Z","iopub.status.idle":"2024-02-20T06:17:40.730695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    # Training\n    model.train()\n    total_train_loss, total_train_correct = 0, 0\n    train_progress_bar = tqdm(train_dataloader, desc=f\"Epoch {epoch + 1} [Training]\", position=0, leave=True)\n    for batch in train_progress_bar:\n        input_ids, attention_masks, labels = (batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"labels\"].to(device))\n\n        optimizer.zero_grad()\n\n        # Use autocast to automatically cast tensor types for mixed precision training\n        with ctx:\n            outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n            loss = criterion(outputs.logits, labels)\n        if mixed_precision_dtype:\n            # Scale the loss and backpropagate with the help of GradScaler\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n        else:\n            loss.backward()\n            optimizer.step()\n\n        total_train_loss += loss.item()\n        preds = torch.argmax(outputs.logits, dim=1)\n        total_train_correct += (preds == labels).sum().item()\n        \n    avg_train_loss = total_train_loss / len(train_dataloader)\n    avg_train_accuracy = total_train_correct / len(encoded_train_dataset)\n    print(f\"Epoch {epoch + 1}, Train Loss: {avg_train_loss}, Train Accuracy: {avg_train_accuracy}\")\n\n    \n    # Evaluation\n    model.eval()\n    total_eval_loss, total_eval_correct = 0, 0\n    eval_progress_bar = tqdm(eval_dataloader, desc=f\"Epoch {epoch + 1} [Evaluation]\", position=0, leave=True)\n    for batch in eval_progress_bar:\n        input_ids, attention_masks, labels = (batch[\"input_ids\"].to(device), batch[\"attention_mask\"].to(device), batch[\"labels\"].to(device))\n\n        with torch.no_grad():\n            with ctx:\n                outputs = model(input_ids, attention_mask=attention_masks, labels=labels)\n                loss = criterion(outputs.logits, labels)\n        total_eval_loss += loss.item()\n        preds = torch.argmax(outputs.logits, dim=1)\n        total_eval_correct += (preds == labels).sum().item()\n\n    avg_eval_loss = total_eval_loss / len(eval_dataloader)\n    avg_eval_accuracy = total_eval_correct / len(encoded_eval_dataset)\n    print(f\"Epoch {epoch + 1}, Evaluation Loss: {avg_eval_loss}, Evaluation Accuracy: {avg_eval_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-02-20T06:17:40.731919Z","iopub.execute_input":"2024-02-20T06:17:40.732232Z","iopub.status.idle":"2024-02-20T06:18:29.696542Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Epoch 1 [Training]: 100%|██████████| 38/38 [00:15<00:00,  2.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Train Loss: 0.6983088443153783, Train Accuracy: 0.5331375838926175\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1 [Evaluation]: 100%|██████████| 11/11 [00:01<00:00,  8.90it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1, Evaluation Loss: 0.6822684407234192, Evaluation Accuracy: 0.5562043795620438\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Training]: 100%|██████████| 38/38 [00:14<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Train Loss: 0.6732683683696546, Train Accuracy: 0.5641778523489933\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2 [Evaluation]: 100%|██████████| 11/11 [00:01<00:00,  8.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2, Evaluation Loss: 0.6756156953898343, Evaluation Accuracy: 0.5518248175182482\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Training]: 100%|██████████| 38/38 [00:14<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Train Loss: 0.6141160663805509, Train Accuracy: 0.6577181208053692\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3 [Evaluation]: 100%|██████████| 11/11 [00:01<00:00,  8.52it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch 3, Evaluation Loss: 0.8228270519863475, Evaluation Accuracy: 0.5635036496350365\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]}]}